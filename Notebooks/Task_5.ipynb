{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX7WilnK7k55"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Install dependencies ---\n",
        "!pip install mlflow scikit-learn xgboost lightgbm\n",
        "\n",
        "# --- Step 2: Imports ---\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# --- Step 3: Load Task 4 dataset ---\n",
        "df = pd.read_csv(\"/content/processed_task4.csv\")\n",
        "\n",
        "# Drop non-numeric passthroughs (IDs, datetimes)\n",
        "drop_cols = [\"is_high_risk\",\"CustomerId\",\"remainder__FirstTxn\",\"remainder__LastTxn\"]\n",
        "X = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "y = df[\"is_high_risk\"]\n",
        "\n",
        "# Train/test split with reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- Step 4: Define models and hyperparameter grids ---\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"LogisticRegression\": {\"C\": [0.1, 1, 10]},\n",
        "    \"RandomForest\": {\"n_estimators\": [50, 100], \"max_depth\": [None, 5, 10]},\n",
        "    \"XGBoost\": {\"n_estimators\": [50, 100], \"max_depth\": [3, 5], \"learning_rate\": [0.1, 0.01]}\n",
        "}\n",
        "\n",
        "# --- Step 5: Train, tune, and log with MLflow ---\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    grid = GridSearchCV(model, param_grids[name], cv=3, scoring=\"f1\", n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_model = grid.best_estimator_\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_prob = best_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "        \"roc_auc\": roc_auc_score(y_test, y_prob)\n",
        "    }\n",
        "\n",
        "    # MLflow logging\n",
        "    with mlflow.start_run(run_name=name):\n",
        "        mlflow.log_params(grid.best_params_)\n",
        "        mlflow.log_metrics(metrics)\n",
        "        mlflow.sklearn.log_model(best_model, name)\n",
        "\n",
        "    print(f\"{name} metrics:\", metrics)\n"
      ]
    }
  ]
}